---
title: "LABORATÓRIO 3: 
        \n Regressão Linear - Desemprego nos EUA entre 1950 a 2019"
author: Fernando Bispo, Jeff Caponero
format:
    pdf:
      toc: true
      toc-title: Sumário
      colorlinks: true
      documentclass: report
      papersize: letter
      number-sections: false
---


\newpage

## Introdução

O presente relatório tem como objetivo a introdução das técnicas de Regressão Linear Simples e a pratica da elaboração de relatórios analíticos fundamentadas na Análise Exploratória de Dados, na resolução de análises conforme os pré-requisitos solicitados para um conjunto de dados.




## Apresentação

Será realizada uma análise sobre um levantamento das taxas de desemprego e o
índice de suicídios nos EUA para o período de 1950 a 2019, para o qual o índice de suicídios foi calculado para cada 1000 habitantes.

As variáveis contidas no arquivo "desemprego.csv" são:

:::{.incrementyal}
- Ano (**ano**);
- Taxa de Desemprego por 1000 habitantes (**desemp**);
- Taxa de Suicídio por 1000 habitantes  (**suic**).
:::


## Objetivos

O objetivo dessa análise visa responder aos seguintes tópicos:

:::{.incrementyal}
(a) Faça as análises necessárias para verificar se suicídios é função linear do desemprego.  
(b) Obtenha ainda as estimativas das variâncias de $\beta_0$ e $\beta_1$.  
(c) Teste a significância do modelo. Que conclusões você chegou com um nível de significância de 5%?  
(d) Obtenha os intervalos de confianças para os parâmetros do modelo com o nível de 95% de confiança. Interprete os resultados.  
:::

## Análise dos dados

### Análise Prévia

Inicialmente vamos verificar as principais medidas resumo dos dados apresentados e verificar a viabilidade gráfica de realizar uma regressão linear a partir dos dados fornecidos.


```{r pacotes}
#| echo: false
#| warning: false


set.seed(7)
setwd("~/Dropbox/Estatística/StatisticWorks/Desemprego_EUA_1950-2019")

library(pacman)

pacman::p_load(tidyverse,  janitor, stargazer,  sjmisc, summarytools,
               kableExtra, moments, ggpubr, formattable, gridExtra, 
               glue, corrplot, sessioninfo, readxl, writexl, ggthemes,
               patchwork,  plotly, lmtest, olsrr, gglm, ggplot2,
               tidymodels, GGally, hrbrthemes)

dados <- read.csv2("desemprego.csv")

dados <- dados |> 
  mutate(
    ano = as.numeric(ano),
    desemp = as.numeric(desemp),
    suic = as.numeric(suic),
  )
```


```{r}
#| echo: false
#| warning: false
#| tbl-colum: page
#| fig-pos: H


dados|>
  rename(
      "Ano" = ano, "T.Desemprego" = desemp, "T.Suicídio" = suic)|>
  select (T.Desemprego,T.Suicídio) |>
  summarytools::descr(
      stats = c("min", "q1", "med", "mean","q3", "max",  "sd", "cv"),
      justify = "c",
      style = "grid",
      transpose = T
  )|>
  kbl(
    caption = "Medidas resumo das taxas de desemprego e suicídio, \n nos EUA de 1950 a 2019",
    digits = 2,
    format.args=list(big.mark=".", decimal.mark=","),
    align = "c",
    row.names = T,
    col.names =
      c("Min", "Q1", "Med", "Média", "Q3", "Max", "D. Padrão", "CV")
  ) |>
  kable_material(c("striped", "hover", "condensed"))|>
  kable_styling(
    bootstrap_options = c("striped", "hover",  "condensed"),
    full_width = F,
    position = 'center', latex_options = 'HOLD_position'
  ) |>
  kable_material()
```


As medidas resumo das taxas de desemprego e suicídio avaliadas não apresetam valores incompatíveis com a análise de regressão linear pretendida, além de mostrarem uma provável normalidade dos dados.


```{r}
#| echo: false
#| warning: false
#| fig-align: center
#| fig-pos: H

b1 <- dados|>
  
  ggplot(aes(y = desemp)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = 'Taxa de Desemprego',
    y = "Desempregados por 1000"
  ) +
  scale_y_continuous(
    labels = scales::number_format(
      dig.mark = ".",
      decimal.mark = ","))


b2 <- dados|>
  ggplot(aes(y = suic)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = 'Taxa de Suicídio',
    y = "Suicídio por 1000"
  ) +
  scale_y_continuous(
    labels = scales::number_format(
      dig.mark = ".",
      decimal.mark = ","))


b1+b2 + plot_annotation(
  title = "Figura 1: BoxPlots das taxas de desemprego e suicídio, \n nos EUA de 1950 a 2019") &
  theme_bw(base_size = 8) &
  theme(
    legend.position = "none",
    plot.tag.position = c(0, 1),
    plot.tag = element_text(size = 8, hjust = 0, vjust = 0)
  )

```

A análise dos BoxPlots, um pouco mais informativa, uma vez que agora é possível verificar que não há valores notadamente discrepantes que poderiam influir negativamente na regressão linear. A provável normalidade dos dados verrificada nas medicadas ateriores não parece ter sido afetada pela análise desses gráficos, uma vez que ainda se pode identificar certa simetria nos dados. Entretanto, faz-se necessário a verificação de tal característica, o que será apresentado a seguir.





```{r}
#| echo: false
#| warning: false
#| fig-align: center
#| fig-pos: H


d1 <- dados |>
  ggplot(aes(
    y = desemp, 
    x = suic, color = suic)) +
  geom_point()+
  labs(
    title = '',
    y = 'Taxa de Desemprego',
    x = 'Taxa de Suicídio'
  )+
  scale_y_continuous(
    labels = scales::number_format(
      big.mark = ".",
      decimal.mark = ","
    ))

d1 + plot_annotation(
  title = "Figura 2: Relação entre Taxa de Desemprego e a Taxa de Suicídio  \n entre 1950 e 2019, nos EUA") &
  theme_bw(base_size = 8) &
  theme(
    legend.position = "none",
    plot.tag.position = c(0, 1),
    plot.tag = element_text(size = 8, hjust = 0, vjust = 0)
  )
```

A dispersão de pontos mostrada na Figura 2 não indica visualmente uma tendência linear entre as duas variáveis analizadas, o que pode comprometer todos os resultados seguintes. Adimitindo que os dados realmente possam ser explicados por uma regressão linear serão realizados as demais análises.

### Regressão Linear

Desta forma, uma possível reta que apresenta a regressão linear dos dados é mostrada na figura a seguir.

```{r}
#| echo: false
#| warning: false
#| tbl-colum: page

d1<- dados |>
  ggplot(aes(
    y = desemp, 
    x = suic, color = suic)) +
  geom_point()+
  labs(
    title = '',
    y = 'Taxa de Desemprego',
    x = 'Taxa de Suicídio'
  )+
  scale_y_continuous(
    labels = scales::number_format(
      big.mark = ".",
      decimal.mark = ","
    ))+
  geom_smooth(method=lm, se=FALSE)

d1+plot_annotation(
  title = "Figura 3: Relação entre Taxa de Desemprego e a Taxa de Suicídio  \n entre 1950 e 2019, nos EUA e sua regressão linear.") &
  theme_bw(base_size = 8) &
  theme(
    legend.position = "none",
    plot.tag.position = c(0, 1),
    plot.tag = element_text(size = 8, hjust = 0, vjust = 0)
  )
```


```{r}
#| warning: false
#| eval: true
#| results: false
#| echo: false

x = dados$suic
y = dados$desemp
n = length(x)
beta1 = (sum(x*y) - as.numeric(sum(x)) * as.numeric(sum(y))/n) /
  (sum(x^2) - ((sum (x))^2)/n)
beta0 = mean(y) - beta1 * mean(x)
beta0 = round(beta0,3)
beta1 = round(beta1,3)
```

### Estimativas Pontuais

A partir do método de Estimativas de Mínimos Quadrados, pode se obter uma estimativa pontuais para $\hat\beta_0$ = `r beta0` e para  $\hat\beta_1$ = `r beta1`.  

### Intervalos de Confiança

A partir dos dados é possível obter um intervalo de confiança para as estimativas obtidas. No modelo de regressão linear simples as estimativas $\hat\beta_0$ e $\hat\beta_1$ têm distribuição de student, e portanto, pelo método da quantidade pivotal é possível determinar seu intervalo de confiança.  


```{r}
#| warning: false
#| eval: true
#| results: false
#| echo: false

t.tab = dt(0.025,n-2)
s.xix = sum((x-mean(x))^2)
ic.beta1 = t.tab*var(y)/(sqrt(s.xix))
ic.beta0 = t.tab*var(y)*sqrt(sum(x^2))/(sqrt(n*s.xix))
li.b0 = beta0 - ic.beta0
ls.b0 = beta0 + ic.beta0
li.b1 = beta1 - ic.beta1
ls.b1 = beta1 + ic.beta1
li.b0 = round(li.b0, 3)
ls.b0 = round(ls.b0, 3)
li.b1 = round(li.b1, 3)
ls.b1 = round(ls.b1, 3)
```

Procedendo com esses cálculos temos que o intervalo de confiança para $\hat\beta_0$ é [`r li.b0`, `r ls.b0`] e o intervalo de confiança de $\hat\beta_1$ é [`r li.b1`, `r ls.b1`], para um nível de confiança de 95%. É importante notar que o intervalo calculado de $\hat\beta_0$ é bastante largo, compreendendo inclusive valores negativos o que não faz sentido para os dados analizados, logo um itervalo de confiança mais realista para $\hat\beta_0$ é [0, `r ls.b0`].


```{r}
#| warning: false
#| eval: true
#| results: false
#| echo: false

rho = (sum(x*y) - (sum(x)*sum(y)/n)) /
  (sqrt((sum(x^2) - ((sum(x))^2)/n)*(sum(y^2)- ((sum (y))^2)/n)))

rho = round(rho,3)

t = rho*sqrt((n-2)/(1-rho^2))
t.tab = dt(0.025,n-2)
t = round(t,4)
t.tab = round(t.tab,4)
resp = "não deverá"
if (abs(t)>abs(t.tab)) resp = "deverá"
```

### Teste de Significância

Como vimos anteriormente, a avaliação gráfica da dispersão dos dados não indica claramente uma relação linear entre os dados avaliados. Entretanto, pode-se realizar um teste de significância do modelo a fim de melhor compreender quão adequado é esse modelo.  
Tomando o método dos mínimos quadrados, estimou-se o valor do coeficiente de correlação linear dos dados $\hat \rho$ = `r rho`. Em seguida calculou-se o valor da estatística temos que $t$ = `r t`. Verificou-se que o valor tabelado dessa estatística $t_{(n-1);\alpha/2} =$ `r t.tab`. Por fim, comparando os valores absolutos dessas estatísticas, verificamos que a hipótese de correlação nula `r resp` ser rejeitada, ao nível de significância de $\alpha =5\%$.  
Outra forma de avaliar a siguinificância do modelo é realizar uma análise gráfica dos resíduos do modelo.

### Residuos versus valores ajustados

```{r}
#| warning: false
#| eval: true
#| results: false
#| echo: false
m1 <- lm(y ~ x)
res <- residuals(m1)
t.bc <- MASS::boxcox(m1)
lambda <- t.bc$x[which.max(t.bc$y)]
 
```

### Testes de diagnóstico

Pode-se ainda utilizar um conjunto de testes de diagnóstico para completar o diagnóstico gráfico dos resíduos. Como:  

:::{.incrementyal}
- Teste de Kolmogorov-Smirnov  
- Teste de Shapiro-Wilks  
- Teste de Goldfeld-Quandt  
- Teste de Breush-Pagan  
- Teste de Park  
- Teste F para linearidade
- Teste para avaliação da independência dos resíduos  
:::

```{r}
#| warning: false
#| eval: true
#| results: false
#| echo: false
t.ks = ks.test(res, "pnorm", mean(res), sd(res))
```


##### Teste de Kolmogorov-Smirnov

Avalia o grau de concordância entre a distribuição de um conjunto de valores observados e determinada distribuição teórica. Consiste em comparar a distribuição de frequência acumulada da distribuição teórica com aquela observada. Realizado o teste obteve-se um p-valor de `r round(t.ks[[2]][1],3)`, o que inviabiliza rejeitar a hipótese de que haja normalidade entre os dados, com um grau de confiabilidade minimamente razoável.

##### Teste de Shapiro-Wilks



```{r}
#| warning: false
#| eval: true
#| results: false
#| echo: false

t.sw = shapiro.test(res)

```
O teste de Shapiro-Wilks é um procedimento alternativo ao teste de Kolmogorov-Smirnov para avaliar normalidade. Realizado o teste obteve-se um p-valor de `r round(t.sw[[2]][1],3)`, o que, semelhantemente, inviabiliza rejeitar a hipótese de que haja normalidade entre os dados, com um grau de confiabilidade minimamente razoável.

##### Teste de Goldfeld-Quandt


```{r}
#| warning: false
#| eval: true
#| results: false
#| echo: false

t.gq = gqtest(m1)

```
Esse teste envolve o ajuste de dois modelos de regressão, separando-se as observações das duas extremidades da distribuição da variável dependente. Realizado o teste obteve-se um p-valor de `r round(t.gq[[5]][1],3)`, o que inviabiliza rejeitar a hipótese de que haja homocedasticidade entre os dados, com um grau de confiabilidade de 95%.

##### Teste de Breush-Pagan

```{r}
#| warning: false
#| eval: true
#| results: false
#| echo: false

t.bp = bptest(m1, studentize = FALSE)
```
Esse teste é baseado no ajuste de um modelo de regressão em que a variável dependente é definida pelos resíduos do modelo de interesse. Se grande parte da variabilidade dos resíduos é explicada pelo modelo, então rejeita-se a hipótese de homocedasticidade. Realizado o teste obteve-se um p-valor de `r round(t.bp[[4]][1],3)`, desta foram deve-se rejeitar a explicação dada pelo teste, assim, não se pode rejeitar a  hipótese de que haja homocedasticidade entre os dados, com um grau de confiabilidade minimamente razoável.

##### Teste de Park 

```{r}
#| warning: false
#| eval: true
#| results: false
#| echo: false
res2 <- res^2
t.p = summary(lm(res2 ~ x))
```

Esse teste é baseado no ajuste de um modelo de regressão em que a variável dependente é definida pelos quadrados dos resíduos do modelo de interesse. Nesse caso, se $\beta_1$ diferir significativamente de zero, rejeita-se a hipótese de homocedasticidade. O valor de $\beta_1$ obtido no teste foi de `r round(t.p[[4]][2],3)` com p-valor de `r round(t.p[[4]][8],3)`. Por esse teste deve-se rejeitar a hipótese de homocedasticidade, com confiabilidade de 95%.

##### Teste F para linearidade

```{r}
#| warning: false
#| eval: true
#| results: false
#| echo: false
m_kmedias <- lm(y ~ factor(x))
t.fl = anova(m1, m_kmedias)
```
O teste da falta de ajuste permite testar formalmente a adequação do ajuste do modelo de regressão. Neste ponto assumimos que os pressupostos de normalidade, variância constante e independência são satisfeitos. A ideia central para testar a linearidade é decompor SQRes em duas partes: erro puro e falta de ajuste que vão contribuir para a definição da estatística de teste F. Realizado o teste obteve-se um valore de p-vaçor igual a `r round(t.fl[[6]][2],3)`, o que inviabiliza a rejeição da hipótese que há uma relação linear entre as variáveis.

##### Teste para avaliação da independência dos resíduos

```{r}
#| warning: false
#| eval: true
#| results: false
#| echo: false
t.dw = dwtest(m1)
```

O teste para avaliação da independência dos resíduos é utilizado para detectar a presença de autocorrelação provenientes de análise de regressão. Realizando o teste obteve-se um valor de p-valor aproximadadente igual a  `r round(t.dw[[4]][1],3)`, indicando que se deve rejeitar a hipotese que não existe correlação serial entre os dados, com uma confiança de 95%.


## Conclusão
